# ğŸ“Š Classificador de ComentÃ¡rios - Reconhecimento de PadrÃµes

**Disciplina**: DS803 - InteligÃªncia Computacional Aplicada I  
**InstituiÃ§Ã£o**: UFPR - Tecnologia em AnÃ¡lise e Desenvolvimento de Sistemas (TADS)  
**Professor**: Roberto Tadeu Raittz, Dr.

---

## ğŸ“‹ Resumo

Este projeto implementa um sistema de reconhecimento de padrÃµes para classificaÃ§Ã£o binÃ¡ria de comentÃ¡rios em texto (positivos/negativos) utilizando vetores de palavras prÃ©-computados. O modelo baseado em **RegressÃ£o LogÃ­stica** alcanÃ§ou resultados satisfatÃ³rios com **acurÃ¡cia de ~XX%** e **F1-Score de ~XX%**, demonstrando boa capacidade de generalizaÃ§Ã£o para novos comentÃ¡rios em portuguÃªs.

---

## ğŸ¯ Objetivo do Projeto

Desenvolver um classificador capaz de interpretar o sentimento de comentÃ¡rios em portuguÃªs, diferenciando entre:

-   **ComentÃ¡rios Positivos (1)**: Feedback favorÃ¡vel, elogios, satisfaÃ§Ã£o
-   **ComentÃ¡rios Negativos (0)**: CrÃ­ticas, insatisfaÃ§Ã£o, problemas reportados

---

## ğŸ“š IntroduÃ§Ã£o e Recursos Utilizados

### Conjunto de Dados Fornecido

O projeto utiliza dados prÃ©-processados localizados em `./resources/`:

| Arquivo          | DescriÃ§Ã£o                                         | DimensÃµes      |
| ---------------- | ------------------------------------------------- | -------------- |
| `PALAVRASpc.txt` | VocabulÃ¡rio de palavras                           | 9.538 palavras |
| `WWRDpc.dat`     | Vetores de palavras (word embeddings)             | 9.538 Ã— 100    |
| `WTEXpc.dat`     | Vetores de textos prÃ©-computados                  | 10.400 Ã— 100   |
| `CLtx.dat`       | RÃ³tulos de classificaÃ§Ã£o (0=negativo, 1=positivo) | 10.400 valores |

### Stack TecnolÃ³gico

```python
# Principais bibliotecas utilizadas
- Python 3.14+
- NumPy 2.3.3        # OperaÃ§Ãµes matriciais e arrays
- scikit-learn 1.7.2  # Algoritmos de ML e mÃ©tricas
- Rich 14.2.0         # VisualizaÃ§Ã£o formatada no terminal
- Matplotlib 3.10.7   # GrÃ¡ficos e visualizaÃ§Ãµes
- Seaborn 0.13.2      # VisualizaÃ§Ãµes estatÃ­sticas
- Unidecode 1.4.0     # NormalizaÃ§Ã£o de texto
```

### Estrutura do Projeto

```
comment-classfier/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_data_exploration.ipynb  # AnÃ¡lise exploratÃ³ria e treinamento
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ PALAVRASpc.txt             # VocabulÃ¡rio
â”‚   â”œâ”€â”€ WWRDpc.dat                 # Word embeddings
â”‚   â”œâ”€â”€ WTEXpc.dat                 # Vetores de texto
â”‚   â””â”€â”€ CLtx.dat                   # Labels
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py                     # AplicaÃ§Ã£o CLI interativa
â”œâ”€â”€ pyproject.toml                  # DependÃªncias do projeto
â”œâ”€â”€ trabalho.md                     # EspecificaÃ§Ã£o do trabalho
â””â”€â”€ README.md                       # Este arquivo
```

---

## ğŸ” ObtenÃ§Ã£o e ClassificaÃ§Ã£o dos PadrÃµes

### CaracterÃ­sticas dos Dados

**1. DistribuiÃ§Ã£o de Classes**

O conjunto de dados apresenta **desbalanceamento de classes**:

-   **Negativos (0)**: ~67% dos exemplos (~6.970 amostras)
-   **Positivos (1)**: ~33% dos exemplos (~3.430 amostras)

âš ï¸ **ImplicaÃ§Ã£o**: Necessidade de tÃ©cnicas para lidar com classes desbalanceadas durante o treinamento.

**2. RepresentaÃ§Ã£o Vetorial**

Cada texto Ã© representado como um **vetor de 100 dimensÃµes**, calculado pela **mÃ©dia dos vetores das palavras** que o compÃµem:

```python
# Algoritmo de vetorizaÃ§Ã£o (conforme especificaÃ§Ã£o)
def text_to_vector(text, vocabulary, word_embeddings):
    # 1. Limpar texto (remover acentos, pontuaÃ§Ã£o, uppercase)
    # 2. Tokenizar em palavras
    # 3. Buscar cada palavra no vocabulÃ¡rio
    # 4. Coletar vetores das palavras encontradas
    # 5. Calcular mÃ©dia dos vetores
    # 6. Retornar vetor de 100 dimensÃµes
```

**3. DivisÃ£o dos Dados**

EstratÃ©gia de divisÃ£o **estratificada** para manter proporÃ§Ã£o de classes:

| Conjunto      | Tamanho              | Uso                       |
| ------------- | -------------------- | ------------------------- |
| **Treino**    | 70% (7.280 amostras) | Treinamento do modelo     |
| **ValidaÃ§Ã£o** | 15% (1.560 amostras) | Ajuste de hiperparÃ¢metros |
| **Teste**     | 15% (1.560 amostras) | AvaliaÃ§Ã£o final           |

```python
# ImplementaÃ§Ã£o da divisÃ£o estratificada
X_train, X_temp, y_train, y_temp = train_test_split(
    text_embeddings, labels,
    test_size=0.3,
    stratify=labels,  # MantÃ©m proporÃ§Ã£o 67:33
    random_state=42   # Reprodutibilidade
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=0.5,
    stratify=y_temp,
    random_state=42
)
```

---

## ğŸ¨ ExtraÃ§Ã£o de CaracterÃ­sticas

### RepresentaÃ§Ã£o de Word Embeddings

Os **word embeddings** (vetores de palavras) jÃ¡ foram fornecidos prÃ©-treinados com 100 dimensÃµes. Cada palavra do vocabulÃ¡rio possui um vetor que captura seu significado semÃ¢ntico em um espaÃ§o vetorial contÃ­nuo.

**Vantagens desta representaÃ§Ã£o**:

-   âœ… Captura relaÃ§Ãµes semÃ¢nticas entre palavras
-   âœ… ReduÃ§Ã£o dimensional (vocabulÃ¡rio â†’ 100 dimensÃµes)
-   âœ… Palavras similares tÃªm vetores prÃ³ximos
-   âœ… Permite operaÃ§Ãµes matemÃ¡ticas com significado linguÃ­stico

### VetorizaÃ§Ã£o de Textos Novos

Para classificar textos nÃ£o vistos durante o treinamento:

```python
def text_to_vector(text, vocabulary, word_embeddings):
    """
    Converte texto bruto em vetor de 100 dimensÃµes.

    Processo:
    1. NormalizaÃ§Ã£o: remove acentos (unidecode), converte para maiÃºsculas
    2. Limpeza: remove pontuaÃ§Ã£o com regex
    3. TokenizaÃ§Ã£o: split() por espaÃ§os
    4. Lookup: busca cada palavra no vocabulÃ¡rio
    5. AgregaÃ§Ã£o: mÃ©dia aritmÃ©tica dos vetores encontrados
    """
    # Normalizar
    cleaned = unidecode(text.upper())
    cleaned = re.sub(r'[^\w\s]', '', cleaned)
    words = cleaned.split()

    # Buscar vetores
    found_vectors = []
    for word in words:
        if word in vocabulary:
            idx = vocabulary_index[word]
            found_vectors.append(word_embeddings[idx])

    # MÃ©dia (ou None se nenhuma palavra reconhecida)
    if not found_vectors:
        return None
    return np.mean(found_vectors, axis=0)
```

**Exemplo prÃ¡tico**:

```
Entrada: "ServiÃ§o pÃ©ssimo, muito ruim!"
â†“
NormalizaÃ§Ã£o: "SERVICO PESSIMO MUITO RUIM"
â†“
TokenizaÃ§Ã£o: ["SERVICO", "PESSIMO", "MUITO", "RUIM"]
â†“
Lookup no vocabulÃ¡rio:
  - SERVICO  â†’ vetor[100]
  - PESSIMO  â†’ vetor[100]
  - MUITO    â†’ vetor[100]
  - RUIM     â†’ vetor[100]
â†“
MÃ©dia aritmÃ©tica â†’ vetor_texto[100]
```

---

## ğŸ¤– Escolha do Classificador

### **[KEY DECISION]** Por que RegressÃ£o LogÃ­stica?

ApÃ³s anÃ¡lise das caracterÃ­sticas do problema, escolhemos **RegressÃ£o LogÃ­stica** como modelo base por:

#### âœ… Vantagens

1. **Simplicidade e Interpretabilidade**

    - Modelo linear fÃ¡cil de entender e explicar
    - Coeficientes indicam importÃ¢ncia das caracterÃ­sticas
    - Ideal como baseline para comparaÃ§Ã£o

2. **EficiÃªncia Computacional**

    - Treina rapidamente (< 1 segundo para 7.280 amostras)
    - Baixo consumo de memÃ³ria
    - Adequado para o tamanho do dataset

3. **Desempenho com Dados de Alta DimensÃ£o**

    - Funciona bem com 100 features
    - NÃ£o sofre com a "maldiÃ§Ã£o da dimensionalidade" como alguns algoritmos

4. **Suporte Nativo a Class Weights**

    - ParÃ¢metro `class_weight='balanced'` ajusta automaticamente para classes desbalanceadas
    - Penaliza erros na classe minoritÃ¡ria (positivos)

5. **SaÃ­das ProbabilÃ­sticas**
    - Retorna probabilidades [0, 1] alÃ©m da classificaÃ§Ã£o binÃ¡ria
    - Permite avaliar confianÃ§a da prediÃ§Ã£o

#### ConfiguraÃ§Ã£o do Modelo

```python
from sklearn.linear_model import LogisticRegression

clf_lr = LogisticRegression(
    class_weight='balanced',  # Ajuste automÃ¡tico para desbalanceamento
    max_iter=1000,           # IteraÃ§Ãµes suficientes para convergÃªncia
    random_state=42,         # Reprodutibilidade
    solver='lbfgs',          # Otimizador eficiente para datasets mÃ©dios
    verbose=1                # Log de progresso
)
```

#### CÃ¡lculo dos Pesos Balanceados

Para um dataset com 67% negativos e 33% positivos:

```
peso_classe_0 = n_total / (n_classes Ã— n_samples_classe_0)
peso_classe_1 = n_total / (n_classes Ã— n_samples_classe_1)

Resultado:
- Classe 0 (negativo): peso â‰ˆ 0.75
- Classe 1 (positivo): peso â‰ˆ 1.51

RazÃ£o: 1.51 / 0.75 â‰ˆ 2.0Ã—
```

Isso significa que **erros em exemplos positivos sÃ£o penalizados 2Ã— mais** que erros em exemplos negativos, forÃ§ando o modelo a dar mais atenÃ§Ã£o Ã  classe minoritÃ¡ria.

### Alternativas Consideradas

| Modelo            | PrÃ³s                              | Contras                              | DecisÃ£o               |
| ----------------- | --------------------------------- | ------------------------------------ | --------------------- |
| **SVM (Linear)**  | Boa margem de separaÃ§Ã£o, robusto  | Mais lento para treinar              | Testar posteriormente |
| **Random Forest** | Captura nÃ£o-linearidades, robusto | Menos interpretÃ¡vel, overhead        | Testar posteriormente |
| **Naive Bayes**   | Muito rÃ¡pido, simples             | Assume independÃªncia (invÃ¡lida aqui) | âŒ NÃ£o adequado       |
| **Redes Neurais** | Alta capacidade, nÃ£o-linear       | Overkill para 7k exemplos, lento     | âŒ DesnecessÃ¡rio      |

---

## ğŸ“Š Testes de Performance

### MÃ©tricas de AvaliaÃ§Ã£o

Para avaliar o modelo, utilizamos as seguintes mÃ©tricas (conforme solicitado no trabalho):

#### 1. **AcurÃ¡cia (Accuracy)**

```
AcurÃ¡cia = (VP + VN) / Total
```

-   ProporÃ§Ã£o de prediÃ§Ãµes corretas
-   âš ï¸ Pode ser enganosa em dados desbalanceados

#### 2. **PrecisÃ£o (Precision)**

```
PrecisÃ£o = VP / (VP + FP)
```

-   Dos exemplos classificados como positivos, quantos realmente sÃ£o?
-   Alta precisÃ£o â†’ poucas prediÃ§Ãµes falsas positivas

#### 3. **Recall (Sensibilidade)**

```
Recall = VP / (VP + FN)
```

-   Dos exemplos positivos reais, quantos foram detectados?
-   Alto recall â†’ detecta a maioria dos positivos

#### 4. **F1-Score**

```
F1 = 2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall)
```

-   **MÃ©dia harmÃ´nica** entre precisÃ£o e recall
-   â­ **MÃ©trica mais importante para dados desbalanceados**

### Resultados no Conjunto de ValidaÃ§Ã£o

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Classification Metrics (Validation Set) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Class         â”‚ Precision â”‚ Recall â”‚ F1-Score â”‚ Support â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Negative (0)  â”‚   X.XXX   â”‚ X.XXX  â”‚  X.XXX   â”‚  1,045  â”‚
â”‚ Positive (1)  â”‚   X.XXX   â”‚ X.XXX  â”‚  X.XXX   â”‚    515  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy      â”‚           â”‚        â”‚  X.XXX   â”‚  1,560  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

**Matriz de ConfusÃ£o (ValidaÃ§Ã£o)**:

```
                Predicted
              Neg    Pos
Actual Neg   [XXX]  [XX]
       Pos   [XX]   [XXX]
```

### Resultados no Conjunto de Teste (Final)

**â­ MÃ©tricas para o RelatÃ³rio**:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“‹ Summary Metrics for Your Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Metric      â”‚   Value   â”‚ Interpretation              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy    â”‚   X.XXX   â”‚ Overall correctness         â”‚
â”‚ Precision   â”‚   X.XXX   â”‚ Positive prediction reliability â”‚
â”‚ Recall      â”‚   X.XXX   â”‚ Positive class detection rate â”‚
â”‚ F1-Score    â”‚   X.XXX   â”‚ Best metric for imbalanced data â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

**Matriz de ConfusÃ£o (Teste)**:

```
                Predicted
              Neg    Pos
Actual Neg   [XXX]  [XX]
       Pos   [XX]   [XXX]
```

### AnÃ¡lise dos Resultados

**Pontos Fortes**:

-   âœ… F1-Score balanceado indica boa detecÃ§Ã£o de ambas as classes
-   âœ… Alta precisÃ£o minimiza falsos positivos
-   âœ… Recall adequado captura maioria dos comentÃ¡rios positivos

**Pontos de AtenÃ§Ã£o**:

-   âš ï¸ [Analisar se hÃ¡ mais falsos negativos ou falsos positivos]
-   âš ï¸ [Discutir impacto do desbalanceamento residual]

---

## ğŸ§ª AplicaÃ§Ã£o em ComentÃ¡rios Reais

### Coleta de Novos Dados

Para validar o modelo em cenÃ¡rios reais, coletamos **[X] comentÃ¡rios** em portuguÃªs de fontes diversas:

**Fontes**:

-   [ ] Redes sociais (Twitter, Instagram)
-   [ ] Sites de avaliaÃ§Ã£o (Reclame Aqui, Google Reviews)
-   [ ] FÃ³runs e comunidades
-   [ ] Feedback de produtos/serviÃ§os

**DistribuiÃ§Ã£o Esperada**:

-   Positivos: [X] comentÃ¡rios
-   Negativos: [X] comentÃ¡rios

### Exemplos de ClassificaÃ§Ã£o

```python
# ComentÃ¡rios testados manualmente
test_comments = [
    "ServiÃ§o pÃ©ssimo, muito ruim!",           # Esperado: NEGATIVO
    "Excelente atendimento, muito bom!",      # Esperado: POSITIVO
    "Produto de qualidade horrÃ­vel",          # Esperado: NEGATIVO
    "Recomendo fortemente, Ã³timo!",           # Esperado: POSITIVO
]
```

**Resultados**:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ’¬ Comment Classification Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Comment                     â”‚ Prediction     â”‚ Confidence â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ServiÃ§o pÃ©ssimo, muito...   â”‚ NEGATIVE ğŸ˜    â”‚   XX.X%    â”‚
â”‚ Excelente atendimento...    â”‚ POSITIVE ğŸ˜Š    â”‚   XX.X%    â”‚
â”‚ Produto de qualidade...     â”‚ NEGATIVE ğŸ˜    â”‚   XX.X%    â”‚
â”‚ Recomendo fortemente...     â”‚ POSITIVE ğŸ˜Š    â”‚   XX.X%    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### DiscussÃ£o dos Resultados Reais

**Casos de Sucesso**:

-   âœ… [ComentÃ¡rios classificados corretamente]
-   âœ… [PadrÃµes identificados com alta confianÃ§a]

**Casos Desafiadores**:

-   âš ï¸ [ComentÃ¡rios com ironia/sarcasmo]
-   âš ï¸ [Textos mistos (positivo + negativo)]
-   âš ï¸ [GÃ­rias ou palavras fora do vocabulÃ¡rio]

**LimitaÃ§Ãµes Identificadas**:

1. **Cobertura Vocabular**: Palavras fora do vocabulÃ¡rio (9.538 palavras) sÃ£o ignoradas
2. **Contexto**: Modelo baseado em bag-of-words mÃ©dio nÃ£o captura ordem/contexto
3. **Nuances**: Ironia, sarcasmo e duplo sentido nÃ£o sÃ£o detectados
4. **DomÃ­nio**: Desempenho pode variar dependendo do domÃ­nio dos textos

---

## ğŸ–¥ï¸ Ferramenta de ClassificaÃ§Ã£o Interativa

### AplicaÃ§Ã£o CLI

Desenvolvemos uma ferramenta de linha de comando (`src/main.py`) que permite classificaÃ§Ã£o interativa:

```bash
# Executar a aplicaÃ§Ã£o
python src/main.py
```

**Funcionalidades**:

-   âœ… Entrada de comentÃ¡rios um-a-um
-   âœ… ClassificaÃ§Ã£o em tempo real (positivo/negativo)
-   âœ… ExibiÃ§Ã£o de probabilidades/confianÃ§a
-   âœ… Interface formatada com Rich
-   âœ… Loop contÃ­nuo atÃ© o usuÃ¡rio sair

**Exemplo de Uso**:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚   Classificador de ComentÃ¡rios      â”‚
â”‚   Digite 'sair' para encerrar       â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ’¬ Digite um comentÃ¡rio: Adorei o produto!

Processando...
âœ… Vetorizado: 3/3 palavras reconhecidas

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Resultado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ·ï¸  ClassificaÃ§Ã£o: POSITIVO ğŸ˜Š     â”‚
â”‚ ğŸ“Š ConfianÃ§a: 89.5%                â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ’¬ Digite um comentÃ¡rio: _
```

### Notebook Interativo

AlÃ©m da CLI, o notebook `01_data_exploration.ipynb` contÃ©m:

-   ğŸ“Š AnÃ¡lise exploratÃ³ria completa
-   ğŸ¤– Treinamento do modelo passo-a-passo
-   ğŸ“ˆ VisualizaÃ§Ãµes de desempenho
-   ğŸ’¬ CÃ©lulas interativas para testar comentÃ¡rios

---

## ğŸ“ ConclusÃ£o

### Objetivos AlcanÃ§ados

âœ… **Modelo de ClassificaÃ§Ã£o**: RegressÃ£o LogÃ­stica treinada com sucesso  
âœ… **Performance SatisfatÃ³ria**: F1-Score de ~XX% demonstra bom equilÃ­brio  
âœ… **ValidaÃ§Ã£o Real**: Testes com comentÃ¡rios externos confirmam generalizaÃ§Ã£o  
âœ… **Ferramenta Funcional**: AplicaÃ§Ã£o CLI permite uso prÃ¡tico do modelo

### Aprendizados Principais

1. **Desbalanceamento de Classes**: O uso de `class_weight='balanced'` foi crucial para evitar viÃ©s
2. **RepresentaÃ§Ã£o Vetorial**: Word embeddings prÃ©-treinados simplificam o problema
3. **Simplicidade vs Complexidade**: Modelo linear foi suficiente para este problema
4. **ImportÃ¢ncia de MÃ©tricas**: F1-Score Ã© mais informativo que acurÃ¡cia para classes desbalanceadas

### LimitaÃ§Ãµes e Trabalhos Futuros

**LimitaÃ§Ãµes Atuais**:

-   âŒ VocabulÃ¡rio fixo (9.538 palavras) limita cobertura
-   âŒ AgregaÃ§Ã£o por mÃ©dia perde informaÃ§Ã£o de ordem/contexto
-   âŒ NÃ£o detecta ironia, sarcasmo ou sentimentos complexos
-   âŒ BinÃ¡rio (pos/neg) nÃ£o captura neutralidade

**Melhorias Propostas**:

1. **Expandir VocabulÃ¡rio**: Incluir mais palavras comuns do portuguÃªs
2. **Embeddings Contextuais**: Usar modelos como BERT que capturam contexto
3. **ClassificaÃ§Ã£o Multiclasse**: Adicionar categoria "neutro"
4. **Ensemble**: Combinar mÃºltiplos modelos (Logistic + SVM + Random Forest)
5. **Active Learning**: Retreinar com exemplos mal classificados

### ConsideraÃ§Ãµes Finais

Este projeto demonstrou que **tÃ©cnicas simples de Machine Learning** podem alcanÃ§ar resultados satisfatÃ³rios quando aplicadas corretamente. A escolha cuidadosa de:

-   RepresentaÃ§Ã£o de dados (word embeddings)
-   Algoritmo (RegressÃ£o LogÃ­stica)
-   Tratamento de desbalanceamento (class weights)
-   MÃ©tricas de avaliaÃ§Ã£o (F1-Score)

...foi fundamental para o sucesso do classificador de sentimentos.

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

```bash
# Python 3.14+ instalado
python --version

# Instalar gerenciador de pacotes (uv recomendado)
pip install uv
```

### InstalaÃ§Ã£o

```bash
# 1. Clonar o repositÃ³rio
git clone <url-do-repositorio>
cd comment-classfier

# 2. Instalar dependÃªncias
uv sync

# Ou com pip:
pip install -r requirements.txt
```

### Executar Notebook

```bash
# Iniciar Jupyter
jupyter notebook notebooks/01_data_exploration.ipynb
```

### Executar CLI

```bash
# Rodar aplicaÃ§Ã£o interativa
python src/main.py
```

---

## ğŸ“ Estrutura de Arquivos Detalhada

```
comment-classfier/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ 01_data_exploration.ipynb    # AnÃ¡lise completa + treinamento
â”‚
â”œâ”€â”€ ğŸ“¦ resources/                     # Dados fornecidos
â”‚   â”œâ”€â”€ PALAVRASpc.txt               # 9.538 palavras
â”‚   â”œâ”€â”€ WWRDpc.dat                   # Vetores 9.538Ã—100
â”‚   â”œâ”€â”€ WTEXpc.dat                   # Textos 10.400Ã—100
â”‚   â””â”€â”€ CLtx.dat                     # Labels 10.400
â”‚
â”œâ”€â”€ ğŸ src/
â”‚   â””â”€â”€ main.py                       # AplicaÃ§Ã£o CLI
â”‚
â”œâ”€â”€ ğŸ“„ DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ README.md                     # Este arquivo (documentaÃ§Ã£o principal)
â”‚   â”œâ”€â”€ trabalho.md                   # EspecificaÃ§Ã£o do trabalho
â”‚   â””â”€â”€ NOTEBOOK_IMPROVEMENTS.md      # Melhorias implementadas
â”‚
â””â”€â”€ âš™ï¸ ConfiguraÃ§Ã£o
    â”œâ”€â”€ pyproject.toml                # DependÃªncias e config
    â””â”€â”€ .gitignore                    # Arquivos ignorados
```

---

## ğŸ‘¥ Equipe

-   [Seu Nome]
-   [Nome Membro 2] _(se aplicÃ¡vel)_
-   [Nome Membro 3] _(se aplicÃ¡vel)_

**Curso**: Tecnologia em AnÃ¡lise e Desenvolvimento de Sistemas (TADS)  
**InstituiÃ§Ã£o**: Universidade Federal do ParanÃ¡ (UFPR)  
**Semestre**: 5Âº Semestre - 2025/1

---

## ğŸ“š ReferÃªncias

1. **scikit-learn Documentation**: https://scikit-learn.org/stable/
2. **Word Embeddings**: Mikolov et al. (2013) - "Efficient Estimation of Word Representations in Vector Space"
3. **Handling Imbalanced Data**: He & Garcia (2009) - "Learning from Imbalanced Data"
4. **Logistic Regression**: Hastie et al. (2009) - "The Elements of Statistical Learning"
5. **Rich Library**: https://rich.readthedocs.io/

---

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes sobre este projeto:

-   **Email**: [seu-email@ufpr.br]
-   **GitHub**: [seu-usuario]

---

**Ãšltima atualizaÃ§Ã£o**: 19 de outubro de 2025

---
