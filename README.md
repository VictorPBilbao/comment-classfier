# üìä Classificador de Coment√°rios - Reconhecimento de Padr√µes

**Disciplina**: DS803 - Intelig√™ncia Computacional Aplicada I  
**Institui√ß√£o**: UFPR - Tecnologia em An√°lise e Desenvolvimento de Sistemas (TADS)  
**Professor**: Roberto Tadeu Raittz, Dr.

---

## üìã Resumo

Este projeto implementa um sistema de reconhecimento de padr√µes para classifica√ß√£o bin√°ria de coment√°rios em texto (positivos/negativos) utilizando vetores de palavras pr√©-computados. O modelo baseado em **Regress√£o Log√≠stica** alcan√ßou resultados satisfat√≥rios com **acur√°cia de ~XX%** e **F1-Score de ~XX%**, demonstrando boa capacidade de generaliza√ß√£o para novos coment√°rios em portugu√™s.

---

## üéØ Objetivo do Projeto

Desenvolver um classificador capaz de interpretar o sentimento de coment√°rios em portugu√™s, diferenciando entre:

-   **Coment√°rios Positivos (1)**: Feedback favor√°vel, elogios, satisfa√ß√£o
-   **Coment√°rios Negativos (0)**: Cr√≠ticas, insatisfa√ß√£o, problemas reportados

---

## üìö Introdu√ß√£o e Recursos Utilizados

### Conjunto de Dados Fornecido

O projeto utiliza dados pr√©-processados localizados em `./resources/`:

| Arquivo          | Descri√ß√£o                                         | Dimens√µes      |
| ---------------- | ------------------------------------------------- | -------------- |
| `PALAVRASpc.txt` | Vocabul√°rio de palavras                           | 9.538 palavras |
| `WWRDpc.dat`     | Vetores de palavras (word embeddings)             | 9.538 √ó 100    |
| `WTEXpc.dat`     | Vetores de textos pr√©-computados                  | 10.400 √ó 100   |
| `CLtx.dat`       | R√≥tulos de classifica√ß√£o (0=negativo, 1=positivo) | 10.400 valores |

### Stack Tecnol√≥gico

```python
# Principais bibliotecas utilizadas
- Python 3.14+
- NumPy 2.3.3        # Opera√ß√µes matriciais e arrays
- scikit-learn 1.7.2  # Algoritmos de ML e m√©tricas
- Rich 14.2.0         # Visualiza√ß√£o formatada no terminal
- Matplotlib 3.10.7   # Gr√°ficos e visualiza√ß√µes
- Seaborn 0.13.2      # Visualiza√ß√µes estat√≠sticas
- Unidecode 1.4.0     # Normaliza√ß√£o de texto
```

### Estrutura do Projeto

```
comment-classfier/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01_data_exploration.ipynb  # An√°lise explorat√≥ria e treinamento
‚îú‚îÄ‚îÄ resources/
‚îÇ   ‚îú‚îÄ‚îÄ PALAVRASpc.txt             # Vocabul√°rio
‚îÇ   ‚îú‚îÄ‚îÄ WWRDpc.dat                 # Word embeddings
‚îÇ   ‚îú‚îÄ‚îÄ WTEXpc.dat                 # Vetores de texto
‚îÇ   ‚îî‚îÄ‚îÄ CLtx.dat                   # Labels
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                     # Aplica√ß√£o CLI interativa
‚îú‚îÄ‚îÄ pyproject.toml                  # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ trabalho.md                     # Especifica√ß√£o do trabalho
‚îî‚îÄ‚îÄ README.md                       # Este arquivo
```

---

## üîç Obten√ß√£o e Classifica√ß√£o dos Padr√µes

### Caracter√≠sticas dos Dados

**1. Distribui√ß√£o de Classes**

O conjunto de dados apresenta **desbalanceamento de classes**:

-   **Negativos (0)**: ~67% dos exemplos (~6.970 amostras)
-   **Positivos (1)**: ~33% dos exemplos (~3.430 amostras)

‚ö†Ô∏è **Implica√ß√£o**: Necessidade de t√©cnicas para lidar com classes desbalanceadas durante o treinamento.

**2. Representa√ß√£o Vetorial**

Cada texto √© representado como um **vetor de 100 dimens√µes**, calculado pela **m√©dia dos vetores das palavras** que o comp√µem:

```python
# Algoritmo de vetoriza√ß√£o (conforme especifica√ß√£o)
def text_to_vector(text, vocabulary, word_embeddings):
    # 1. Limpar texto (remover acentos, pontua√ß√£o, uppercase)
    # 2. Tokenizar em palavras
    # 3. Buscar cada palavra no vocabul√°rio
    # 4. Coletar vetores das palavras encontradas
    # 5. Calcular m√©dia dos vetores
    # 6. Retornar vetor de 100 dimens√µes
```

**3. Divis√£o dos Dados**

Estrat√©gia de divis√£o **estratificada** para manter propor√ß√£o de classes:

| Conjunto      | Tamanho              | Uso                       |
| ------------- | -------------------- | ------------------------- |
| **Treino**    | 70% (7.280 amostras) | Treinamento do modelo     |
| **Valida√ß√£o** | 15% (1.560 amostras) | Ajuste de hiperpar√¢metros |
| **Teste**     | 15% (1.560 amostras) | Avalia√ß√£o final           |

```python
# Implementa√ß√£o da divis√£o estratificada
X_train, X_temp, y_train, y_temp = train_test_split(
    text_embeddings, labels,
    test_size=0.3,
    stratify=labels,  # Mant√©m propor√ß√£o 67:33
    random_state=42   # Reprodutibilidade
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=0.5,
    stratify=y_temp,
    random_state=42
)
```

---

## üé® Extra√ß√£o de Caracter√≠sticas

### Representa√ß√£o de Word Embeddings

Os **word embeddings** (vetores de palavras) j√° foram fornecidos pr√©-treinados com 100 dimens√µes. Cada palavra do vocabul√°rio possui um vetor que captura seu significado sem√¢ntico em um espa√ßo vetorial cont√≠nuo.

**Vantagens desta representa√ß√£o**:

-   ‚úÖ Captura rela√ß√µes sem√¢nticas entre palavras
-   ‚úÖ Redu√ß√£o dimensional (vocabul√°rio ‚Üí 100 dimens√µes)
-   ‚úÖ Palavras similares t√™m vetores pr√≥ximos
-   ‚úÖ Permite opera√ß√µes matem√°ticas com significado lingu√≠stico

### Vetoriza√ß√£o de Textos Novos

Para classificar textos n√£o vistos durante o treinamento:

```python
def text_to_vector(text, vocabulary, word_embeddings):
    """
    Converte texto bruto em vetor de 100 dimens√µes.

    Processo:
    1. Normaliza√ß√£o: remove acentos (unidecode), converte para mai√∫sculas
    2. Limpeza: remove pontua√ß√£o com regex
    3. Tokeniza√ß√£o: split() por espa√ßos
    4. Lookup: busca cada palavra no vocabul√°rio
    5. Agrega√ß√£o: m√©dia aritm√©tica dos vetores encontrados
    """
    # Normalizar
    cleaned = unidecode(text.upper())
    cleaned = re.sub(r'[^\w\s]', '', cleaned)
    words = cleaned.split()

    # Buscar vetores
    found_vectors = []
    for word in words:
        if word in vocabulary:
            idx = vocabulary_index[word]
            found_vectors.append(word_embeddings[idx])

    # M√©dia (ou None se nenhuma palavra reconhecida)
    if not found_vectors:
        return None
    return np.mean(found_vectors, axis=0)
```

**Exemplo pr√°tico**:

```
Entrada: "Servi√ßo p√©ssimo, muito ruim!"
‚Üì
Normaliza√ß√£o: "SERVICO PESSIMO MUITO RUIM"
‚Üì
Tokeniza√ß√£o: ["SERVICO", "PESSIMO", "MUITO", "RUIM"]
‚Üì
Lookup no vocabul√°rio:
  - SERVICO  ‚Üí vetor[100]
  - PESSIMO  ‚Üí vetor[100]
  - MUITO    ‚Üí vetor[100]
  - RUIM     ‚Üí vetor[100]
‚Üì
M√©dia aritm√©tica ‚Üí vetor_texto[100]
```

---

## ü§ñ Escolha do Classificador

### **[KEY DECISION]** Por que Regress√£o Log√≠stica?

Ap√≥s an√°lise das caracter√≠sticas do problema, escolhemos **Regress√£o Log√≠stica** como modelo base por:

#### ‚úÖ Vantagens

1. **Simplicidade e Interpretabilidade**

    - Modelo linear f√°cil de entender e explicar
    - Coeficientes indicam import√¢ncia das caracter√≠sticas
    - Ideal como baseline para compara√ß√£o

2. **Efici√™ncia Computacional**

    - Treina rapidamente (< 1 segundo para 7.280 amostras)
    - Baixo consumo de mem√≥ria
    - Adequado para o tamanho do dataset

3. **Desempenho com Dados de Alta Dimens√£o**

    - Funciona bem com 100 features
    - N√£o sofre com a "maldi√ß√£o da dimensionalidade" como alguns algoritmos

4. **Suporte Nativo a Class Weights**

    - Par√¢metro `class_weight='balanced'` ajusta automaticamente para classes desbalanceadas
    - Penaliza erros na classe minorit√°ria (positivos)

5. **Sa√≠das Probabil√≠sticas**
    - Retorna probabilidades [0, 1] al√©m da classifica√ß√£o bin√°ria
    - Permite avaliar confian√ßa da predi√ß√£o

#### Configura√ß√£o do Modelo

```python
from sklearn.linear_model import LogisticRegression

clf_lr = LogisticRegression(
    class_weight='balanced',  # Ajuste autom√°tico para desbalanceamento
    max_iter=1000,           # Itera√ß√µes suficientes para converg√™ncia
    random_state=42,         # Reprodutibilidade
    solver='lbfgs',          # Otimizador eficiente para datasets m√©dios
    verbose=1                # Log de progresso
)
```

#### C√°lculo dos Pesos Balanceados

Para um dataset com 67% negativos e 33% positivos:

```
peso_classe_0 = n_total / (n_classes √ó n_samples_classe_0)
peso_classe_1 = n_total / (n_classes √ó n_samples_classe_1)

Resultado:
- Classe 0 (negativo): peso ‚âà 0.75
- Classe 1 (positivo): peso ‚âà 1.51

Raz√£o: 1.51 / 0.75 ‚âà 2.0√ó
```

Isso significa que **erros em exemplos positivos s√£o penalizados 2√ó mais** que erros em exemplos negativos, for√ßando o modelo a dar mais aten√ß√£o √† classe minorit√°ria.

### Alternativas Consideradas

| Modelo            | Pr√≥s                              | Contras                              | Decis√£o               |
| ----------------- | --------------------------------- | ------------------------------------ | --------------------- |
| **SVM (Linear)**  | Boa margem de separa√ß√£o, robusto  | Mais lento para treinar              | Testar posteriormente |
| **Random Forest** | Captura n√£o-linearidades, robusto | Menos interpret√°vel, overhead        | Testar posteriormente |
| **Naive Bayes**   | Muito r√°pido, simples             | Assume independ√™ncia (inv√°lida aqui) | ‚ùå N√£o adequado       |
| **Redes Neurais** | Alta capacidade, n√£o-linear       | Overkill para 7k exemplos, lento     | ‚ùå Desnecess√°rio      |

---

## üìä Testes de Performance

### M√©tricas de Avalia√ß√£o

Para avaliar o modelo, utilizamos as seguintes m√©tricas (conforme solicitado no trabalho):

#### 1. **Acur√°cia (Accuracy)**

```
Acur√°cia = (VP + VN) / Total
```

-   Propor√ß√£o de predi√ß√µes corretas
-   ‚ö†Ô∏è Pode ser enganosa em dados desbalanceados

#### 2. **Precis√£o (Precision)**

```
Precis√£o = VP / (VP + FP)
```

-   Dos exemplos classificados como positivos, quantos realmente s√£o?
-   Alta precis√£o ‚Üí poucas predi√ß√µes falsas positivas

#### 3. **Recall (Sensibilidade)**

```
Recall = VP / (VP + FN)
```

-   Dos exemplos positivos reais, quantos foram detectados?
-   Alto recall ‚Üí detecta a maioria dos positivos

#### 4. **F1-Score**

```
F1 = 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)
```

-   **M√©dia harm√¥nica** entre precis√£o e recall
-   ‚≠ê **M√©trica mais importante para dados desbalanceados**

### Resultados no Conjunto de Valida√ß√£o

```
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Classification Metrics (Validation Set) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Class         ‚îÇ Precision ‚îÇ Recall ‚îÇ F1-Score ‚îÇ Support ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Negative (0)  ‚îÇ   X.XXX   ‚îÇ X.XXX  ‚îÇ  X.XXX   ‚îÇ  1,045  ‚îÇ
‚îÇ Positive (1)  ‚îÇ   X.XXX   ‚îÇ X.XXX  ‚îÇ  X.XXX   ‚îÇ    515  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Accuracy      ‚îÇ           ‚îÇ        ‚îÇ  X.XXX   ‚îÇ  1,560  ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

**Matriz de Confus√£o (Valida√ß√£o)**:

```
                Predicted
              Neg    Pos
Actual Neg   [XXX]  [XX]
       Pos   [XX]   [XXX]
```

### Resultados no Conjunto de Teste (Final)

**‚≠ê M√©tricas para o Relat√≥rio**:

```
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üìã Summary Metrics for Your Report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Metric      ‚îÇ   Value   ‚îÇ Interpretation              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Accuracy    ‚îÇ   X.XXX   ‚îÇ Overall correctness         ‚îÇ
‚îÇ Precision   ‚îÇ   X.XXX   ‚îÇ Positive prediction reliability ‚îÇ
‚îÇ Recall      ‚îÇ   X.XXX   ‚îÇ Positive class detection rate ‚îÇ
‚îÇ F1-Score    ‚îÇ   X.XXX   ‚îÇ Best metric for imbalanced data ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

**Matriz de Confus√£o (Teste)**:

```
                Predicted
              Neg    Pos
Actual Neg   [XXX]  [XX]
       Pos   [XX]   [XXX]
```

### An√°lise dos Resultados

**Pontos Fortes**:

-   ‚úÖ F1-Score balanceado indica boa detec√ß√£o de ambas as classes
-   ‚úÖ Alta precis√£o minimiza falsos positivos
-   ‚úÖ Recall adequado captura maioria dos coment√°rios positivos

**Pontos de Aten√ß√£o**:

-   ‚ö†Ô∏è [Analisar se h√° mais falsos negativos ou falsos positivos]
-   ‚ö†Ô∏è [Discutir impacto do desbalanceamento residual]

---

## üß™ Aplica√ß√£o em Coment√°rios Reais

### Coleta de Novos Dados

Para validar o modelo em cen√°rios reais, coletamos **[X] coment√°rios** em portugu√™s de fontes diversas:

**Fontes**:

-   [ ] Redes sociais (Twitter, Instagram)
-   [ ] Sites de avalia√ß√£o (Reclame Aqui, Google Reviews)
-   [ ] F√≥runs e comunidades
-   [ ] Feedback de produtos/servi√ßos

**Distribui√ß√£o Esperada**:

-   Positivos: [X] coment√°rios
-   Negativos: [X] coment√°rios

### Exemplos de Classifica√ß√£o

```python
# Coment√°rios testados manualmente
test_comments = [
    "Servi√ßo p√©ssimo, muito ruim!",           # Esperado: NEGATIVO
    "Excelente atendimento, muito bom!",      # Esperado: POSITIVO
    "Produto de qualidade horr√≠vel",          # Esperado: NEGATIVO
    "Recomendo fortemente, √≥timo!",           # Esperado: POSITIVO
]
```

**Resultados**:

```
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üí¨ Comment Classification Results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Comment                     ‚îÇ Prediction     ‚îÇ Confidence ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Servi√ßo p√©ssimo, muito...   ‚îÇ NEGATIVE üòû    ‚îÇ   XX.X%    ‚îÇ
‚îÇ Excelente atendimento...    ‚îÇ POSITIVE üòä    ‚îÇ   XX.X%    ‚îÇ
‚îÇ Produto de qualidade...     ‚îÇ NEGATIVE üòû    ‚îÇ   XX.X%    ‚îÇ
‚îÇ Recomendo fortemente...     ‚îÇ POSITIVE üòä    ‚îÇ   XX.X%    ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

### Discuss√£o dos Resultados Reais

**Casos de Sucesso**:

-   ‚úÖ [Coment√°rios classificados corretamente]
-   ‚úÖ [Padr√µes identificados com alta confian√ßa]

**Casos Desafiadores**:

-   ‚ö†Ô∏è [Coment√°rios com ironia/sarcasmo]
-   ‚ö†Ô∏è [Textos mistos (positivo + negativo)]
-   ‚ö†Ô∏è [G√≠rias ou palavras fora do vocabul√°rio]

**Limita√ß√µes Identificadas**:

1. **Cobertura Vocabular**: Palavras fora do vocabul√°rio (9.538 palavras) s√£o ignoradas
2. **Contexto**: Modelo baseado em bag-of-words m√©dio n√£o captura ordem/contexto
3. **Nuances**: Ironia, sarcasmo e duplo sentido n√£o s√£o detectados
4. **Dom√≠nio**: Desempenho pode variar dependendo do dom√≠nio dos textos

---

## üñ•Ô∏è Ferramenta de Classifica√ß√£o Interativa

### Aplica√ß√£o CLI

Desenvolvemos uma ferramenta de linha de comando (`src/main.py`) que permite classifica√ß√£o interativa:

```bash
# Executar a aplica√ß√£o
python src/main.py
```

**Funcionalidades**:

-   ‚úÖ Entrada de coment√°rios um-a-um
-   ‚úÖ Classifica√ß√£o em tempo real (positivo/negativo)
-   ‚úÖ Exibi√ß√£o de probabilidades/confian√ßa
-   ‚úÖ Interface formatada com Rich
-   ‚úÖ Loop cont√≠nuo at√© o usu√°rio sair

**Exemplo de Uso**:

```
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ   Classificador de Coment√°rios      ‚îÇ
‚îÇ   Digite 'sair' para encerrar       ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

üí¨ Digite um coment√°rio: Adorei o produto!

Processando...
‚úÖ Vetorizado: 3/3 palavras reconhecidas

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Resultado ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ üè∑Ô∏è  Classifica√ß√£o: POSITIVO üòä     ‚îÇ
‚îÇ üìä Confian√ßa: 89.5%                ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

üí¨ Digite um coment√°rio: _
```

### Notebook Interativo

Al√©m da CLI, o notebook `01_data_exploration.ipynb` cont√©m:

-   üìä An√°lise explorat√≥ria completa
-   ü§ñ Treinamento do modelo passo-a-passo
-   üìà Visualiza√ß√µes de desempenho
-   üí¨ C√©lulas interativas para testar coment√°rios

---

## üéì Conclus√£o

### Objetivos Alcan√ßados

‚úÖ **Modelo de Classifica√ß√£o**: Regress√£o Log√≠stica treinada com sucesso  
‚úÖ **Performance Satisfat√≥ria**: F1-Score de ~XX% demonstra bom equil√≠brio  
‚úÖ **Valida√ß√£o Real**: Testes com coment√°rios externos confirmam generaliza√ß√£o  
‚úÖ **Ferramenta Funcional**: Aplica√ß√£o CLI permite uso pr√°tico do modelo

### Aprendizados Principais

1. **Desbalanceamento de Classes**: O uso de `class_weight='balanced'` foi crucial para evitar vi√©s
2. **Representa√ß√£o Vetorial**: Word embeddings pr√©-treinados simplificam o problema
3. **Simplicidade vs Complexidade**: Modelo linear foi suficiente para este problema
4. **Import√¢ncia de M√©tricas**: F1-Score √© mais informativo que acur√°cia para classes desbalanceadas

### Limita√ß√µes e Trabalhos Futuros

**Limita√ß√µes Atuais**:

-   ‚ùå Vocabul√°rio fixo (9.538 palavras) limita cobertura
-   ‚ùå Agrega√ß√£o por m√©dia perde informa√ß√£o de ordem/contexto
-   ‚ùå N√£o detecta ironia, sarcasmo ou sentimentos complexos
-   ‚ùå Bin√°rio (pos/neg) n√£o captura neutralidade

**Melhorias Propostas**:

1. **Expandir Vocabul√°rio**: Incluir mais palavras comuns do portugu√™s
2. **Embeddings Contextuais**: Usar modelos como BERT que capturam contexto
3. **Classifica√ß√£o Multiclasse**: Adicionar categoria "neutro"
4. **Ensemble**: Combinar m√∫ltiplos modelos (Logistic + SVM + Random Forest)
5. **Active Learning**: Retreinar com exemplos mal classificados

### Considera√ß√µes Finais

Este projeto demonstrou que **t√©cnicas simples de Machine Learning** podem alcan√ßar resultados satisfat√≥rios quando aplicadas corretamente. A escolha cuidadosa de:

-   Representa√ß√£o de dados (word embeddings)
-   Algoritmo (Regress√£o Log√≠stica)
-   Tratamento de desbalanceamento (class weights)
-   M√©tricas de avalia√ß√£o (F1-Score)

...foi fundamental para o sucesso do classificador de sentimentos.

---

## üöÄ Como Executar

### Pr√©-requisitos

```bash
# Python 3.14+ instalado
python --version

# Instalar gerenciador de pacotes (uv recomendado)
pip install uv
```

### Instala√ß√£o

```bash
# 1. Clonar o reposit√≥rio
git clone <url-do-repositorio>
cd comment-classfier

# 2. Instalar depend√™ncias
uv sync

# Ou com pip:
pip install -r requirements.txt
```

### Executar Notebook

```bash
# Iniciar Jupyter
jupyter notebook notebooks/01_data_exploration.ipynb
```

### Executar CLI

```bash
# Rodar aplica√ß√£o interativa
python src/main.py
```

---

## üìÅ Estrutura de Arquivos Detalhada

```
comment-classfier/
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01_data_exploration.ipynb    # An√°lise completa + treinamento
‚îÇ
‚îú‚îÄ‚îÄ üì¶ resources/                     # Dados fornecidos
‚îÇ   ‚îú‚îÄ‚îÄ PALAVRASpc.txt               # 9.538 palavras
‚îÇ   ‚îú‚îÄ‚îÄ WWRDpc.dat                   # Vetores 9.538√ó100
‚îÇ   ‚îú‚îÄ‚îÄ WTEXpc.dat                   # Textos 10.400√ó100
‚îÇ   ‚îî‚îÄ‚îÄ CLtx.dat                     # Labels 10.400
‚îÇ
‚îú‚îÄ‚îÄ üêç src/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                       # Aplica√ß√£o CLI
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ README.md                     # Este arquivo (documenta√ß√£o principal)
‚îÇ   ‚îú‚îÄ‚îÄ trabalho.md                   # Especifica√ß√£o do trabalho
‚îÇ   ‚îî‚îÄ‚îÄ NOTEBOOK_IMPROVEMENTS.md      # Melhorias implementadas
‚îÇ
‚îî‚îÄ‚îÄ ‚öôÔ∏è Configura√ß√£o
    ‚îú‚îÄ‚îÄ pyproject.toml                # Depend√™ncias e config
    ‚îî‚îÄ‚îÄ .gitignore                    # Arquivos ignorados
```

---

## üë• Equipe

-   [Seu Nome]
-   [Nome Membro 2] _(se aplic√°vel)_
-   [Nome Membro 3] _(se aplic√°vel)_

**Curso**: Tecnologia em An√°lise e Desenvolvimento de Sistemas (TADS)  
**Institui√ß√£o**: Universidade Federal do Paran√° (UFPR)  
**Semestre**: 5¬∫ Semestre - 2025/1

---

## üìö Refer√™ncias

1. **scikit-learn Documentation**: https://scikit-learn.org/stable/
2. **Word Embeddings**: Mikolov et al. (2013) - "Efficient Estimation of Word Representations in Vector Space"
3. **Handling Imbalanced Data**: He & Garcia (2009) - "Learning from Imbalanced Data"
4. **Logistic Regression**: Hastie et al. (2009) - "The Elements of Statistical Learning"
5. **Rich Library**: https://rich.readthedocs.io/

---

## üìß Contato

Para d√∫vidas ou sugest√µes sobre este projeto:

-   **Email**: [seu-email@ufpr.br]
-   **GitHub**: [seu-usuario]

---

**√öltima atualiza√ß√£o**: 19 de outubro de 2025

---
